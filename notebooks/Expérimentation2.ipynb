{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20671d5d-bf4b-45cc-9b16-3d534a308032",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\"> Test de modèles de Hugging face pour la génération de résumé de texte (summarization)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82738394-3ae0-46f7-81a6-7e990798a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0)\n",
    "\n",
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "020c4c18-498f-4d0f-a2cd-18cec196dbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18916954e7cd485692297f87a611ac8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/265 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4235253559942a3bc93e4d2a6dfb3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0fc281ec3449f48e9f81e63f2cb22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.camembert.modeling_camembert.CamembertModel'> is overwritten by shared encoder config: CamembertConfig {\n",
      "  \"_name_or_path\": \"camembert-base\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.48.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.camembert.modeling_camembert.CamembertForCausalLM'> is overwritten by shared decoder config: CamembertConfig {\n",
      "  \"_name_or_path\": \"camembert-base\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.48.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Aussi j'ai utilisé vos mails efrei. En passant si vous avez le temps, jetez un coup d'œil à ce que vous avez utilisé pour créer vos compte.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizerFast, EncoderDecoderModel\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ckpt = 'mrm8488/camembert2camembert_shared-finetuned-french-summarization'\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(ckpt)\n",
    "model = EncoderDecoderModel.from_pretrained(ckpt).to(device)\n",
    "def generate_summary(text):\n",
    "   inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "   input_ids = inputs.input_ids.to(device)\n",
    "   attention_mask = inputs.attention_mask.to(device)\n",
    "   output = model.generate(input_ids, attention_mask=attention_mask)\n",
    "   return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "   \n",
    "text = \"Un nuage de fumée juste après l’explosion, le 1er juin 2019. Une déflagration dans une importante usine d’explosifs du centre de la Russie a fait au moins 79 blessés samedi 1er juin. L’explosion a eu lieu dans l’usine Kristall à Dzerzhinsk, une ville située à environ 400 kilomètres à l’est de Moscou, dans la région de Nijni-Novgorod. « Il y a eu une explosion technique dans l’un des ateliers, suivie d’un incendie qui s’est propagé sur une centaine de mètres carrés », a expliqué un porte-parole des services d’urgence. Des images circulant sur les réseaux sociaux montraient un énorme nuage de fumée après l’explosion. Cinq bâtiments de l’usine et près de 180 bâtiments résidentiels ont été endommagés par l’explosion, selon les autorités municipales. Une enquête pour de potentielles violations des normes de sécurité a été ouverte. Fragments de shrapnel Les blessés ont été soignés après avoir été atteints par des fragments issus de l’explosion, a précisé une porte-parole des autorités sanitaires citée par Interfax. « Nous parlons de blessures par shrapnel d’une gravité moyenne et modérée », a-t-elle précisé. Selon des représentants de Kristall, cinq personnes travaillaient dans la zone où s’est produite l’explosion. Elles ont pu être évacuées en sécurité. Les pompiers locaux ont rapporté n’avoir aucune information sur des personnes qui se trouveraient encore dans l’usine.\"\n",
    "\n",
    "generate_summary(ARTICLE)\n",
    "\n",
    "# Output: L’explosion a eu lieu dans l’usine Kristall à Dzerzhinsk, une ville située à environ 400 kilomètres à l’est de Moscou.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc176ccb-ef6e-4912-afe0-7a1a77bd129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"J'ai créé une équipe avec Aziz, le nom de l'équipe c'est NSMS ( avec nos comptes de theécole) Je suis encore entrain de réflechir à comment vous les partager vue qu'on ait à distance. SI vous avez des idé proposer hien hien.\"}]\n"
     ]
    }
   ],
   "source": [
    "ARTICLE = \"\"\" ehhhh,tu dois avoir reçu un mail pour que t'accepte l'invitation. Aussi j'ai besoin de vos mails (si vous utiliser Notion les mail que vous avez utiliser pour créer vos compte serais préférable…). Bref j'ai utilisé vos mails efrei. En passant si vous avez le temps, jetez un coup d'œil à ce que j'ai fait sur Notion la. C'est pour nous permettre de mieux gérer et de le faire sans trop se casser la tête….. je vous ait donné les permissions nécessaire pour tout faire ...\n",
    "Et puis comme Aziz n'est pas ici la woo si ya des truc que l'on veux dire par rapport au projet la c'est mieux qu'on le fasse sur Teams. J'ai créé une équipe avec Aziz, le nom de l'équipe c'est NSMS ( avec nos comptes de l'école).En passant j'ai commencer à travailler sur mon coté la ( coté génération de donné la ) Je suis encore entrain de réflechir à comment vous les partager vue qu'on ait à distance … SI vous avez des idé proposer hien\"\"\"\n",
    "print(summarizer([ARTICLE], max_length=330, min_length=10, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f29e7d60-f357-421b-9ff3-fb0a45d5987b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La littérature réaliste permet aux élèves de s’évader temporairement de leur quotidien pour explorer un sujet en consultant des ouvrages informels.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_summary(\"\"\"Les ensembles de textes doivent inclure des ouvrages de fiction et documentaires adéquats sur les\n",
    "plans développemental et culturel. Une variété de ressources documentaires permet aux\n",
    "apprenants de prendre en considération plus d’un point de vue en consultant des ouvrages\n",
    "informels, compréhensibles et authentiques. Les ouvrages de fiction permettent aux élèves de\n",
    "s’évader temporairement de leur quotidien pour explorer un sujet. La fiction réaliste (comme, la\n",
    "science-fiction, la littérature traditionnelle ou folklorique, la poésie, les œuvres théâtrales) peuvent\n",
    "apporter beaucoup au contenu du programme d’études. Les livres illustrés, qu’il s’agisse d’œuvres\n",
    "de fiction ou non, peuvent être utilisés par les élèves comme ressources pour se créer des schémas,\n",
    "pour activer les connaissances antérieures et comme tremplins pour lancer la discussion. Les\n",
    "documents multimédias sont essentiels, car ils sont interactifs, ils permettent aux élèves d’entrer en\n",
    "contact avec d’autres personnes dans le monde, ils facilitent la recherche et la collecte de\n",
    "renseignements, ils sont très stimulants, ils facilitent la compréhension des élèves, ils permettent\n",
    "aux élèves de faire de la conceptualisation dans un climat de collaboration et ils donnent accès à des\n",
    "renseignements à jour et pertinents.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d49ef07-7b55-4a19-a865-d3929acf044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My friends']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFBartForConditionalGeneration\n",
    "\n",
    "model = TFBartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "\n",
    "ARTICLE_TO_SUMMARIZE = \"My friends are cool but they eat too many carbs.\"\n",
    "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors=\"tf\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=5)\n",
    "print(tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184197d6-cf3d-4e36-a051-cad519ae78b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98112435c86149fab743920b1a9087d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanto\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tanto\\.cache\\huggingface\\hub\\models--google--pegasus-xsum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55147cb858e8437ea6455c57780870de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cfe8c77fb441fa92d3598f914dea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac08124df87a44d1a11ac9d16ad6313a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d117031f1cc4fcd8400e305f64dd385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22635c4219674585a5bfe8b114f242a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786fb11682564476b2f1f1c1ffe5b7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6154a2bce0403ebca2c57fc8cb4098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"California's largest electricity provider has turned off power to hundreds of thousands of customers.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "\n",
    "ARTICLE_TO_SUMMARIZE = (\n",
    "    \"PG&E stated it scheduled the blackouts in response to forecasts for high winds \"\n",
    "    \"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were \"\n",
    "    \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
    ")\n",
    "inputs = tokenizer(ARTICLE_TO_SUMMARIZE, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9744785e-9ab3-4f28-bc76-9db7dff420aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C'est pour nous permettre de mieux gérer et de le faire sans tropaire pour tout faire ...\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTICLE_TO_SUMMARIZE = (\n",
    "    \"\"\"\n",
    "Bref j'ai utilisé vos mails efrei. En passant si vous avez le temps, jetez un coup d'œil à ce que j'ai fait sur Notion la. C'est pour nous permettre de mieux gérer et de le faire sans trop se casser la tête….. je vous ait donné les permissions nécessaire pour tout faire ...\n",
    "Et puis comme Aziz n'est pas ici la woo si ya des truc que l'on veux dire par rapport au projet la c'est mieux qu'on le fasse sur Teams. J'ai créé une équipe avec Aziz, le nom de l'équipe c'est NSMS ( avec nos comptes de l'école).En passant j'ai commencer à travailler sur mon coté la ( coté génération de donné la ) Je suis encore entrain de réflechir à comment vous les partager vue qu'on ait à distance … SI vous avez des idé proposer hien\n",
    "    \"\"\"\n",
    ")\n",
    "inputs = tokenizer(ARTICLE_TO_SUMMARIZE, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80072e16-fbfa-4ed4-ac2d-fd979a347deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tanto\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d5022753cf401db069c05b17e22ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanto\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tanto\\.cache\\huggingface\\hub\\models--human-centered-summarization--financial-summarization-pegasus. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e86ac88d6842f09c9e81cf05674b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f71231853f4a46ba20ed88d15e8ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868de6d825ee47e29abbd29b746da7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7170b10e784a42b2947bab7504f0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at human-centered-summarization/financial-summarization-pegasus and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saudi bank to pay a 3.5% premium to Samba share price. Gulf region’s third-largest lender will have total assets of $220 billion\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, TFPegasusForConditionalGeneration\n",
    "\n",
    "# Let's load the model and the tokenizer \n",
    "model_name = \"human-centered-summarization/financial-summarization-pegasus\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name) # If you want to use the Tensorflow model \n",
    "                                                                    # just replace with TFPegasusForConditionalGeneration\n",
    "\n",
    "\n",
    "# Some text to summarize here\n",
    "text_to_summarize = \"National Commercial Bank (NCB), Saudi Arabia’s largest lender by assets, agreed to buy rival Samba Financial Group for $15 billion in the biggest banking takeover this year.NCB will pay 28.45 riyals ($7.58) for each Samba share, according to a statement on Sunday, valuing it at about 55.7 billion riyals. NCB will offer 0.739 new shares for each Samba share, at the lower end of the 0.736-0.787 ratio the banks set when they signed an initial framework agreement in June.The offer is a 3.5% premium to Samba’s Oct. 8 closing price of 27.50 riyals and about 24% higher than the level the shares traded at before the talks were made public. Bloomberg News first reported the merger discussions.The new bank will have total assets of more than $220 billion, creating the Gulf region’s third-largest lender. The entity’s $46 billion market capitalization nearly matches that of Qatar National Bank QPSC, which is still the Middle East’s biggest lender with about $268 billion of assets.\"\n",
    "\n",
    "# Tokenize our text\n",
    "# If you want to run the code in Tensorflow, please remember to return the particular tensors as simply as using return_tensors = 'tf'\n",
    "input_ids = tokenizer(text_to_summarize, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generate the output (Here, we use beam search but you can also use any other strategy you like)\n",
    "output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=32, \n",
    "    num_beams=5, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Finally, we can print the generated summary\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "# Generated Output: Saudi bank to pay a 3.5% premium to Samba share price. Gulf region’s third-largest lender will have total assets of $220 billion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4c1b755-561d-498d-84a7-ed95cf1802ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>Une gestion efficace de contr<unk>ler ses dépenses et d’épargner réguli<unk>rement.</s>\n"
     ]
    }
   ],
   "source": [
    "text_to_summarize = \"\"\"\n",
    "La finance joue un rôle central dans la réussite économique, qu'il s'agisse des finances personnelles ou des entreprises. Une gestion efficace du budget permet de contrôler ses dépenses et d’épargner régulièrement. L’investissement stratégique est essentiel pour faire croître son capital, en tenant compte du risque et du rendement potentiel. La diversification des actifs limite les pertes en répartissant les fonds sur plusieurs secteurs. De plus, il est crucial de se protéger contre l’inflation, qui réduit le pouvoir d’achat au fil du temps. Enfin, une bonne planification financière garantit la stabilité et la sécurité face aux imprévus économiques.\"\"\"\n",
    "input_ids = tokenizer(text_to_summarize, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generate the output (Here, we use beam search but you can also use any other strategy you like)\n",
    "output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=150, \n",
    "    num_beams=5, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Finally, we can print the generated summary\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "# Generated Output: Saudi bank to pay a 3.5% premium to Samba share price. Gulf region’s third-largest lender will have total assets of $220 billion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e9c1b7-880d-4016-9eee-ef283d9b2fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.mt5.tokenization_mt5.MT5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")\n",
    "tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
    "article = \"\"\"ehhhh,tu dois avoir reçu un mail pour que t'accepte l'invitation. Aussi j'ai besoin de vos mails (si vous utiliser Notion les mail que vous avez utiliser pour créer vos compte serais préférable…). Bref j'ai utilisé vos mails efrei. En passant si vous avez le temps, jetez un coup d'œil à ce que j'ai fait sur Notion la. C'est pour nous permettre de mieux gérer et de le faire sans trop se casser la tête….. je vous ait donné les permissions nécessaire pour tout faire ...\n",
    "Et puis comme Aziz n'est pas ici la woo si ya des truc que l'on veux dire par rapport au projet la c'est mieux qu'on le fasse sur Teams. J'ai créé une équipe avec Aziz, le nom de l'équipe c'est NSMS ( avec nos comptes de l'école).En passant j'ai commencer à travailler sur mon coté la ( coté génération de donné la ) Je suis encore entrain de réflechir à comment vous les partager vue qu'on ait à distance … SI vous avez des idé proposer hien\"\"\"\n",
    "summary = \"\"\"L'utilisateur a créé un espace sur Notion pour mieux gérer le projet et a donné les permissions nécessaires. Une équipe \"NSMS\" a aussi été créée sur Teams (avec les comptes de l'école) pour faciliter la communication, notamment avec Aziz. Il travaille sur la génération de données et cherche un moyen efficace de les partager à distance. Suggestions bienvenues.\"\"\"\n",
    "inputs = tokenizer(article, text_target=summary, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "loss = outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14204c09-cb93-4dbb-843b-844572c73619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
